{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 텍스트 전처리 함수\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# MoodyLyrics 데이터 로드\n",
    "data_path = '../data/ml_balanced.xlsx'\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 텍스트와 레이블 추출 및 전처리\n",
    "texts = (df['Artist'].astype(str) + ' ' + df['Title'].astype(str)).apply(clean_text).tolist()\n",
    "labels = df['Mood'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym_replacement(sentence, n):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    return sentence\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym)\n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)\n",
    "\n",
    "def augment_text(texts, labels, num_augmented):\n",
    "    augmented_texts = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for _ in range(num_augmented):\n",
    "        for text, label in zip(texts, labels):\n",
    "            augmented_texts.append(synonym_replacement(text, n=2))\n",
    "            augmented_labels.append(label)\n",
    "    \n",
    "    return augmented_texts, augmented_labels\n",
    "\n",
    "# 텍스트 증강\n",
    "augmented_texts, augmented_labels = augment_text(texts, labels, num_augmented=5)\n",
    "\n",
    "# 증강된 데이터 추가\n",
    "texts.extend(augmented_texts)\n",
    "labels.extend(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 정의 및 텍스트 토큰화\n",
    "num_words = 20000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# 패딩 처리\n",
    "maxlen = 200\n",
    "X = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# 클래스 수 정의\n",
    "num_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe 임베딩 로드\n",
    "embeddings_index = {}\n",
    "glove_path = '../data/glove.6B.100d.txt'  # GloVe 파일 경로\n",
    "with open(glove_path, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# 임베딩 매트릭스 생성\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < num_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m2,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=256, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 288ms/step - accuracy: 0.2377 - loss: 1.4013 - val_accuracy: 0.2362 - val_loss: 1.3878\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.2638 - loss: 1.3887 - val_accuracy: 0.2404 - val_loss: 1.3869\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.2678 - loss: 1.3854 - val_accuracy: 0.2996 - val_loss: 1.3723\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.2903 - loss: 1.3806 - val_accuracy: 0.3533 - val_loss: 1.3451\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 281ms/step - accuracy: 0.3109 - loss: 1.3637 - val_accuracy: 0.3512 - val_loss: 1.3284\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 279ms/step - accuracy: 0.3525 - loss: 1.3174 - val_accuracy: 0.3804 - val_loss: 1.2946\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 282ms/step - accuracy: 0.3959 - loss: 1.2829 - val_accuracy: 0.4071 - val_loss: 1.2516\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 276ms/step - accuracy: 0.4044 - loss: 1.2566 - val_accuracy: 0.4129 - val_loss: 1.2373\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.4188 - loss: 1.2338 - val_accuracy: 0.4492 - val_loss: 1.2067\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.4382 - loss: 1.2056 - val_accuracy: 0.4579 - val_loss: 1.1826\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.4528 - loss: 1.1917 - val_accuracy: 0.4737 - val_loss: 1.1390\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.4773 - loss: 1.1536 - val_accuracy: 0.4979 - val_loss: 1.1283\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 272ms/step - accuracy: 0.4852 - loss: 1.1405 - val_accuracy: 0.4983 - val_loss: 1.1039\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.5066 - loss: 1.1025 - val_accuracy: 0.5408 - val_loss: 1.0755\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.4957 - loss: 1.1044 - val_accuracy: 0.5396 - val_loss: 1.0522\n",
      "Epoch 16/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.5225 - loss: 1.0874 - val_accuracy: 0.5621 - val_loss: 1.0219\n",
      "Epoch 17/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.5313 - loss: 1.0542 - val_accuracy: 0.5604 - val_loss: 1.0090\n",
      "Epoch 18/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 283ms/step - accuracy: 0.5531 - loss: 1.0375 - val_accuracy: 0.5921 - val_loss: 0.9898\n",
      "Epoch 19/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 277ms/step - accuracy: 0.5597 - loss: 1.0179 - val_accuracy: 0.5983 - val_loss: 0.9675\n",
      "Epoch 20/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.5668 - loss: 1.0029 - val_accuracy: 0.6075 - val_loss: 0.9699\n",
      "Epoch 21/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 279ms/step - accuracy: 0.5841 - loss: 0.9687 - val_accuracy: 0.6171 - val_loss: 0.9344\n",
      "Epoch 22/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.5905 - loss: 0.9566 - val_accuracy: 0.6292 - val_loss: 0.9233\n",
      "Epoch 23/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.6144 - loss: 0.9268 - val_accuracy: 0.6408 - val_loss: 0.8991\n",
      "Epoch 24/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.6218 - loss: 0.9098 - val_accuracy: 0.6592 - val_loss: 0.8712\n",
      "Epoch 25/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.6349 - loss: 0.8835 - val_accuracy: 0.6533 - val_loss: 0.8654\n",
      "Epoch 26/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 270ms/step - accuracy: 0.6453 - loss: 0.8706 - val_accuracy: 0.6579 - val_loss: 0.8564\n",
      "Epoch 27/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 271ms/step - accuracy: 0.6709 - loss: 0.8290 - val_accuracy: 0.6658 - val_loss: 0.8555\n",
      "Epoch 28/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.6665 - loss: 0.8261 - val_accuracy: 0.6662 - val_loss: 0.8405\n",
      "Epoch 29/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 273ms/step - accuracy: 0.6752 - loss: 0.8104 - val_accuracy: 0.6779 - val_loss: 0.8240\n",
      "Epoch 30/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.6819 - loss: 0.7989 - val_accuracy: 0.6938 - val_loss: 0.8078\n",
      "Epoch 31/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.6966 - loss: 0.7660 - val_accuracy: 0.6933 - val_loss: 0.7909\n",
      "Epoch 32/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 283ms/step - accuracy: 0.7066 - loss: 0.7401 - val_accuracy: 0.7008 - val_loss: 0.7902\n",
      "Epoch 33/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 274ms/step - accuracy: 0.7225 - loss: 0.7137 - val_accuracy: 0.7100 - val_loss: 0.7607\n",
      "Epoch 34/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 282ms/step - accuracy: 0.7183 - loss: 0.7055 - val_accuracy: 0.7138 - val_loss: 0.7783\n",
      "Epoch 35/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 295ms/step - accuracy: 0.7242 - loss: 0.7079 - val_accuracy: 0.7150 - val_loss: 0.7556\n",
      "Epoch 36/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 289ms/step - accuracy: 0.7394 - loss: 0.6698 - val_accuracy: 0.7237 - val_loss: 0.7574\n",
      "Epoch 37/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 287ms/step - accuracy: 0.7433 - loss: 0.6643 - val_accuracy: 0.7254 - val_loss: 0.7434\n",
      "Epoch 38/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 285ms/step - accuracy: 0.7574 - loss: 0.6252 - val_accuracy: 0.7300 - val_loss: 0.7416\n",
      "Epoch 39/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 298ms/step - accuracy: 0.7550 - loss: 0.6337 - val_accuracy: 0.7400 - val_loss: 0.7168\n",
      "Epoch 40/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 291ms/step - accuracy: 0.7660 - loss: 0.6120 - val_accuracy: 0.7454 - val_loss: 0.7098\n",
      "Epoch 41/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 295ms/step - accuracy: 0.7799 - loss: 0.5857 - val_accuracy: 0.7429 - val_loss: 0.7066\n",
      "Epoch 42/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 289ms/step - accuracy: 0.7719 - loss: 0.5918 - val_accuracy: 0.7500 - val_loss: 0.7108\n",
      "Epoch 43/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 337ms/step - accuracy: 0.8014 - loss: 0.5423 - val_accuracy: 0.7521 - val_loss: 0.7083\n",
      "Epoch 44/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 294ms/step - accuracy: 0.7879 - loss: 0.5608 - val_accuracy: 0.7546 - val_loss: 0.6918\n",
      "Epoch 45/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 295ms/step - accuracy: 0.7929 - loss: 0.5372 - val_accuracy: 0.7558 - val_loss: 0.7065\n",
      "Epoch 46/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 292ms/step - accuracy: 0.8019 - loss: 0.5197 - val_accuracy: 0.7625 - val_loss: 0.7095\n",
      "Epoch 47/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 278ms/step - accuracy: 0.8086 - loss: 0.5086 - val_accuracy: 0.7692 - val_loss: 0.7000\n",
      "Epoch 48/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 290ms/step - accuracy: 0.8125 - loss: 0.5076 - val_accuracy: 0.7675 - val_loss: 0.7146\n",
      "Epoch 49/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 299ms/step - accuracy: 0.8234 - loss: 0.4771 - val_accuracy: 0.7733 - val_loss: 0.7098\n",
      "Epoch 50/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 286ms/step - accuracy: 0.8284 - loss: 0.4695 - val_accuracy: 0.7804 - val_loss: 0.6857\n",
      "Epoch 51/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 303ms/step - accuracy: 0.8253 - loss: 0.4652 - val_accuracy: 0.7825 - val_loss: 0.6862\n",
      "Epoch 52/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 277ms/step - accuracy: 0.8307 - loss: 0.4440 - val_accuracy: 0.7825 - val_loss: 0.6850\n",
      "Epoch 53/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 278ms/step - accuracy: 0.8425 - loss: 0.4334 - val_accuracy: 0.7821 - val_loss: 0.6897\n",
      "Epoch 54/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.8490 - loss: 0.4199 - val_accuracy: 0.7875 - val_loss: 0.6705\n",
      "Epoch 55/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.8457 - loss: 0.4054 - val_accuracy: 0.7904 - val_loss: 0.6790\n",
      "Epoch 56/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 275ms/step - accuracy: 0.8525 - loss: 0.4013 - val_accuracy: 0.7883 - val_loss: 0.6833\n",
      "Epoch 57/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 298ms/step - accuracy: 0.8427 - loss: 0.4221 - val_accuracy: 0.7908 - val_loss: 0.6713\n",
      "Epoch 58/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 285ms/step - accuracy: 0.8550 - loss: 0.3985 - val_accuracy: 0.7954 - val_loss: 0.6804\n",
      "Epoch 59/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 310ms/step - accuracy: 0.8646 - loss: 0.3703 - val_accuracy: 0.7900 - val_loss: 0.6511\n",
      "Epoch 60/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 325ms/step - accuracy: 0.8647 - loss: 0.3772 - val_accuracy: 0.7904 - val_loss: 0.6632\n",
      "Epoch 61/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 311ms/step - accuracy: 0.8689 - loss: 0.3574 - val_accuracy: 0.7892 - val_loss: 0.6824\n",
      "Epoch 62/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 301ms/step - accuracy: 0.8726 - loss: 0.3648 - val_accuracy: 0.7942 - val_loss: 0.6621\n",
      "Epoch 63/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 292ms/step - accuracy: 0.8689 - loss: 0.3656 - val_accuracy: 0.7983 - val_loss: 0.6506\n",
      "Epoch 64/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.8750 - loss: 0.3509 - val_accuracy: 0.8012 - val_loss: 0.6646\n",
      "Epoch 65/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 297ms/step - accuracy: 0.8786 - loss: 0.3396 - val_accuracy: 0.8079 - val_loss: 0.6581\n",
      "Epoch 66/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 292ms/step - accuracy: 0.8851 - loss: 0.3311 - val_accuracy: 0.8029 - val_loss: 0.6687\n",
      "Epoch 67/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 284ms/step - accuracy: 0.8857 - loss: 0.3183 - val_accuracy: 0.8050 - val_loss: 0.6794\n",
      "Epoch 68/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 298ms/step - accuracy: 0.8766 - loss: 0.3359 - val_accuracy: 0.8000 - val_loss: 0.6781\n",
      "Epoch 69/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 308ms/step - accuracy: 0.8885 - loss: 0.3184 - val_accuracy: 0.8008 - val_loss: 0.6642\n",
      "Epoch 70/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 311ms/step - accuracy: 0.8955 - loss: 0.2942 - val_accuracy: 0.8037 - val_loss: 0.6793\n",
      "Epoch 71/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 291ms/step - accuracy: 0.8944 - loss: 0.3066 - val_accuracy: 0.8042 - val_loss: 0.6638\n",
      "Epoch 72/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 307ms/step - accuracy: 0.8933 - loss: 0.2950 - val_accuracy: 0.8112 - val_loss: 0.6723\n",
      "Epoch 73/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 311ms/step - accuracy: 0.9000 - loss: 0.2832 - val_accuracy: 0.8108 - val_loss: 0.7072\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터와 검증용 데이터로 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 조기 종료 콜백 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.7990 - loss: 0.6481\n",
      "Validation Loss: 0.6506103277206421\n",
      "Validation Accuracy: 0.7983333468437195\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {loss}')\n",
    "print(f'Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: c:\\music_recommender\\scripts\\models\\text_classification_model.keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 모델 저장 경로\n",
    "save_dir = os.path.join(os.getcwd(), 'models')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_path = os.path.join(save_dir, 'text_classification_model.keras')\n",
    "\n",
    "# 모델 저장\n",
    "model.save(model_path)\n",
    "print(f'Model saved at: {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
